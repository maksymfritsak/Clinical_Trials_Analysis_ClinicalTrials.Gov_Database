{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caefd1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import patoolib\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305b9737",
   "metadata": {},
   "source": [
    "# Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cbd8fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded dataset with 12488 trials.\n"
     ]
    }
   ],
   "source": [
    "# This dataset was extracted from ClinicalTrials.gov on 15.02.24.\n",
    "# Original .csv file provided as a .rar due to the maximum upload size limitations on GitHub.\n",
    "# With the filter 'cancer' for disease and 'Radiation Therapy' for the intervention/treatment.\n",
    "# While loading, we skip 'bad' lines. \n",
    "\n",
    "rar_path = 'ClinicalTrials_raw_data.rar'\n",
    "\n",
    "destination_dir = '.' \n",
    "patoolib.extract_archive(rar_path, outdir=destination_dir, verbosity = -1)\n",
    "\n",
    "data = pd.read_csv('ClinicalTrials_raw_data.csv', on_bad_lines=\"skip\")\n",
    "data = data.drop(['Study URL', 'Study Documents', 'Last Update Posted',\n",
    "                  'Results First Posted', 'Completion Date', 'Other IDs',\n",
    "                  'Acronym', 'NCT Number', 'Primary Completion Date', 'First Posted',\n",
    "                  'Study Results', 'Primary Outcome Measures',\n",
    "                  'Secondary Outcome Measures', 'Other Outcome Measures',\n",
    "                  'Sponsor', 'Collaborators', 'Brief Summary', 'Enrollment'], axis=1)\n",
    "\n",
    "print(f' Loaded dataset with {data.shape[0]} trials.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3a92b5",
   "metadata": {},
   "source": [
    "# Filtering Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f1f622",
   "metadata": {},
   "source": [
    "### I) Keep Only Trials Started Between 2003 and 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04f22ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trials from the original dataset with start dates between January 1, 2003, and December 31, 2023: 10982 trials.\n"
     ]
    }
   ],
   "source": [
    "filtered_data = data[data['Start Date'].notna()].copy()\n",
    "filtered_data.loc[:, 'Original Conditions'] = filtered_data['Conditions']\n",
    "filtered_data['Start Date'] = filtered_data['Start Date'].astype(str)\n",
    "filtered_data['Year'] = filtered_data['Start Date'].str.split('-').str[0].astype(int)\n",
    "filtered_data = filtered_data[(filtered_data['Year'] >= 2003) & (filtered_data['Year'] <= 2023)]\n",
    "#filtered_data = filtered_data.drop(columns=['Year'])\n",
    "filtered_data['Start Date'] = filtered_data['Start Date'].str.split('-').str[0].astype(int)\n",
    "print(f'Number of trials from the original dataset with start dates between January 1, 2003, and December 31, 2023: {filtered_data.shape[0]} trials.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87292b58",
   "metadata": {},
   "source": [
    "### II) Keep Only Interventional Trials with Treatment as the Primary Purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef452c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of interventional trials with \"treatment\" as the primary purpose from the original dataset: 7887 trials.\n"
     ]
    }
   ],
   "source": [
    "filtered_data = filtered_data[filtered_data['Study Type'] == 'INTERVENTIONAL']\n",
    "filtered_data = filtered_data[filtered_data['Study Design'].str.contains('Primary Purpose: TREATMENT')]\n",
    "print('Number of interventional trials with \"treatment\" as the primary purpose '\n",
    "      f'from the original dataset: {filtered_data.shape[0]} trials.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cab93e0",
   "metadata": {},
   "source": [
    "### III) Remove Any Trials with Essential Information Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccb68a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current number of trials: 6151\n"
     ]
    }
   ],
   "source": [
    "filtered_data = filtered_data[filtered_data['Phases'].notna()]\n",
    "print(f'Current number of trials: {filtered_data.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69ffc77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current number of trials: 6150\n"
     ]
    }
   ],
   "source": [
    "filtered_data = filtered_data[filtered_data['Sex'].notna()]\n",
    "print(f'Current number of trials: {filtered_data.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc178727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current number of trials: 6150\n"
     ]
    }
   ],
   "source": [
    "filtered_data = filtered_data[filtered_data['Age'].notna()]\n",
    "print(f'Current number of trials: {filtered_data.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a5dc65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current number of trials: 5802\n"
     ]
    }
   ],
   "source": [
    "filtered_data = filtered_data[filtered_data['Locations'].notna()]\n",
    "print(f'Current number of trials: {filtered_data.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ef18e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current number of trials: 5795\n"
     ]
    }
   ],
   "source": [
    "filtered_data = filtered_data[filtered_data['Funder Type'] != 'UNKNOWN']\n",
    "print(f'Current number of trials: {filtered_data.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee0bdb3",
   "metadata": {},
   "source": [
    "### IV) Filter out all non-radiation oncology trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c26f4439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case-insensitive function to find specific words in text strings.\n",
    "\n",
    "def find(word, text):\n",
    "    return len(re.findall(r'{}' .format(word), text, re.IGNORECASE))!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "277b50b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists `rt_list` and `exact_rt_list` were defined through the iterative process\n",
    "# of investigating the 'Intervention/Treatment' fields. \n",
    "# This allows for the proper sorting of only the radiation oncology trials (trials that performed radiotherapy).\n",
    "# The 'Intervention/Treatment' field is used because, according to ClinicalTrials.gov,\n",
    "# intervention/treatment refers to any process or action that's the focus of a clinical study. \n",
    "# This includes drugs, medical devices, procedures, vaccines, and other products, whether investigational or available. \n",
    "# Thus, if radiotherapy was involved in the trial, it should be mentioned in 'Intervention/Treatment'.\n",
    "\n",
    "rt_list = ['radiation', 'radiotherapy', 'radiosurgery', 'brachy', 'tomotherapy', 'radiodynamic',\n",
    "              'hypofraction', 'Radiochemo', 'fractionated', 'fractionation', 'conv', 'stereotactic',\n",
    "              'external beam', 'cyberknife', 'simultaneous integrated boost', 'simultaneous boost',\n",
    "              'IMRT', 'VMAT', 'SBRT', 'SABR', 'BNCT', 'IMPT', 'SRS', 'PBI', 'PRDR', 'TBI', 'TLI',\n",
    "              'TSEB', 'HDR', 'PBT', 'SIB', 'WBRT', 'CCRT',\n",
    "              'volume modulated arc therapy', 'pencil beam scanning', \n",
    "              'particle therapy', 'proton', 'carbon', 'electron', 'photon', 'gray']\n",
    "\n",
    "exact_rt_list = ['Gy', 'GY', 'RT', 'EBR', 'radio(-chemo)therapy']\n",
    "\n",
    "for index, _ in filtered_data.iterrows():\n",
    "    intervention = filtered_data['Interventions'][index]\n",
    "    condition = filtered_data['Conditions'][index]\n",
    "    title = filtered_data['Study Title'][index]\n",
    "    \n",
    "    if 'RADIATION:' in intervention:\n",
    "        list_of_interventions = []\n",
    "        for part in intervention.split('|'):\n",
    "            if 'RADIATION:' in part:\n",
    "                list_of_interventions.append(part[10:])\n",
    "        \n",
    "        switch = False\n",
    "        for intervention in list_of_interventions:\n",
    "            \n",
    "            for rt_list_instance in rt_list + ['dose']:\n",
    "                if find(rt_list_instance, intervention):\n",
    "                    switch = True\n",
    "            \n",
    "            for exact_rt_list_instance in exact_rt_list: \n",
    "                if exact_rt_list_instance in intervention:\n",
    "                    switch = True\n",
    "                    \n",
    "        if switch == False:\n",
    "            filtered_data = filtered_data.drop(index)\n",
    "            \n",
    "    else:\n",
    "        switch = False\n",
    "        for rt_list_instance in rt_list:\n",
    "            if find(rt_list_instance, intervention):\n",
    "                switch = True\n",
    "\n",
    "        for exact_rt_list_instance in exact_rt_list: \n",
    "            if exact_rt_list_instance in intervention:\n",
    "                switch = True\n",
    "\n",
    "        if switch == False:\n",
    "            filtered_data = filtered_data.drop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb3ef56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this step, all detected false-positive trials are removed. \n",
    "# Originally, some of false positives were detected not only through\n",
    "# manual filtering steps but also through manual binning steps. \n",
    "# However, now we remove them as part of the filtering phase to keep the next pipeline focused solely on binning.\n",
    "\n",
    "filtered_data = filtered_data.drop(118)\n",
    "filtered_data = filtered_data.drop(388)\n",
    "filtered_data = filtered_data.drop(1022)\n",
    "filtered_data = filtered_data.drop(2425)\n",
    "filtered_data = filtered_data.drop(7277)\n",
    "filtered_data = filtered_data.drop(7642)\n",
    "filtered_data = filtered_data.drop(7926)\n",
    "filtered_data = filtered_data.drop(8368)\n",
    "filtered_data = filtered_data.drop(8643)\n",
    "filtered_data = filtered_data.drop(11581)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dc1bfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the cleaning, we end up with 4253 trials.\n"
     ]
    }
   ],
   "source": [
    "print(f'After the cleaning, we end up with {filtered_data.shape[0]} trials.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a39951",
   "metadata": {},
   "source": [
    "# Binning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d120e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all detected unresolved trials from the entire binning pipeline. \n",
    "# They were identified through manual screening during the different binning phases\n",
    "# and were initially assigned to more than one bin. \n",
    "# After the manual screening, the correct bin was assigned.\n",
    "#\n",
    "# Based on the performed analysis,only less than 1% of trials \n",
    "# needed manual assignment/correction.\n",
    "\n",
    "filtered_data.loc[497, 'Conditions'] = 'FILTERED_CNS'\n",
    "filtered_data.loc[498, 'Conditions'] = 'FILTERED_CNS'\n",
    "filtered_data.loc[790, 'Conditions'] = 'FILTERED_HeadAndNeck'\n",
    "filtered_data.loc[881, 'Conditions'] = 'FILTERED_Digestive'\n",
    "filtered_data.loc[1086, 'Conditions'] = 'FILTERED_Others'\n",
    "filtered_data.loc[1432, 'Conditions'] = 'FILTERED_CNS'\n",
    "filtered_data.loc[1831, 'Conditions'] = 'FILTERED_HeadAndNeck'\n",
    "filtered_data.loc[2066, 'Conditions'] = 'FILTERED_HeadAndNeck'\n",
    "filtered_data.loc[2251, 'Conditions'] = 'FILTERED_HeadAndNeck'\n",
    "filtered_data.loc[2524, 'Conditions'] = 'FILTERED_Genitourinary'\n",
    "filtered_data.loc[2714, 'Conditions'] = 'FILTERED_Genitourinary'\n",
    "filtered_data.loc[3026, 'Conditions'] = 'FILTERED_Digestive'\n",
    "filtered_data.loc[3045, 'Conditions'] = 'FILTERED_Hematology'\n",
    "filtered_data.loc[3263, 'Conditions'] = 'FILTERED_Others'\n",
    "filtered_data.loc[4271, 'Conditions'] = 'FILTERED_Thoracic'\n",
    "filtered_data.loc[4504, 'Conditions'] = 'FILTERED_HeadAndNeck'\n",
    "filtered_data.loc[4568, 'Conditions'] = 'FILTERED_Others'\n",
    "filtered_data.loc[5102, 'Conditions'] = 'FILTERED_HeadAndNeck'\n",
    "filtered_data.loc[5382, 'Conditions'] = 'FILTERED_CNS'\n",
    "filtered_data.loc[5593, 'Conditions'] = 'FILTERED_Others'\n",
    "filtered_data.loc[5722, 'Conditions'] = 'FILTERED_CNS'\n",
    "filtered_data.loc[5816, 'Conditions'] = 'FILTERED_Others'\n",
    "filtered_data.loc[5871, 'Conditions'] = 'FILTERED_Digestive'\n",
    "filtered_data.loc[6153, 'Conditions'] = 'FILTERED_Hematology'\n",
    "filtered_data.loc[6302, 'Conditions'] = 'FILTERED_Digestive'\n",
    "filtered_data.loc[6375, 'Conditions'] = 'FILTERED_Digestive'\n",
    "filtered_data.loc[7245, 'Conditions'] = 'FILTERED_Digestive'\n",
    "filtered_data.loc[7607, 'Conditions'] = 'FILTERED_HeadAndNeck'\n",
    "filtered_data.loc[7713, 'Conditions'] = 'FILTERED_HeadAndNeck'\n",
    "filtered_data.loc[7594, 'Conditions'] = 'FILTERED_Digestive'\n",
    "filtered_data.loc[7936, 'Conditions'] = 'FILTERED_CNS'\n",
    "filtered_data.loc[8281, 'Conditions'] = 'FILTERED_HeadAndNeck'\n",
    "filtered_data.loc[8285, 'Conditions'] = 'FILTERED_HeadAndNeck'\n",
    "filtered_data.loc[9095, 'Conditions'] = 'FILTERED_Hematology'\n",
    "filtered_data.loc[10103, 'Conditions'] = 'FILTERED_Digestive'\n",
    "filtered_data.loc[10614, 'Conditions'] = 'FILTERED_Digestive'\n",
    "filtered_data.loc[10615, 'Conditions'] = 'FILTERED_HeadAndNeck'\n",
    "filtered_data.loc[11003, 'Conditions'] = 'FILTERED_CNS'\n",
    "filtered_data.loc[11031, 'Conditions'] = 'FILTERED_CNS'\n",
    "filtered_data.loc[12154, 'Conditions'] = 'FILTERED_HeadAndNeck'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f98e0e",
   "metadata": {},
   "source": [
    "### I) Find All Oligometastatic (OMD) Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27219562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start with OMD trials because we are not interested in specific locations,\n",
    "# only in the fact that it is an OMD trial.\n",
    "\n",
    "for index, _ in filtered_data.iterrows():\n",
    "    condition = filtered_data['Conditions'][index]\n",
    "    title = filtered_data['Study Title'][index]\n",
    "    if (find('oligomet', title) or find('oligomet', condition) \n",
    "        or find('oligopro', title) or find('oligopro', condition)\n",
    "        or find('oligorec', title) or find('oligorec', condition)\n",
    "        or find('oligo-resid', title) or find('oligo-resid', condition)\n",
    "       ):\n",
    "        filtered_data.loc[index, 'Conditions'] = 'FILTERED_Oligometastatic'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cae7e0f",
   "metadata": {},
   "source": [
    "### II) Find Trials That Belong to the \"Others\" Bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bed6722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we proceed with specific words for the \"Others\" bin,\n",
    "# as it is easier to sort out the rest of the bins afterwards.\n",
    "# The list of `filtered_others_definitions` was defined through \n",
    "# the iterative process of binning to decrease \n",
    "# the amount of manual screening in subsequent steps.\n",
    "# The `filtered_others_definitions` list is specific to this dataset.\n",
    "\n",
    "filtered_others_definitions = ['osteosarcoma', 'lentigo maligna', 'basal cell', 'rhabdomyosarcoma', \n",
    "                               'soft tissue sarcoma', 'retroperitoneal sarcoma', 'skin cancer',\n",
    "                               'liposarcoma', 'angiosarcoma', 'ewing', 'merkel','retinoblastoma',\n",
    "                               'neuroblastoma', 'chordoma']\n",
    "\n",
    "for index, _ in filtered_data.iterrows():\n",
    "    condition = filtered_data['Conditions'][index]\n",
    "    title = filtered_data['Study Title'][index]\n",
    "    for filtered_word in filtered_others_definitions:\n",
    "        if 'FILTERED_' not in condition and (find(filtered_word, title) or find(filtered_word, condition)):    \n",
    "            filtered_data.loc[index, 'Conditions'] = 'FILTERED_Others'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8492843",
   "metadata": {},
   "source": [
    "### III) Find All Metastatic Trials That Belong to the CNS Bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31e55d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering in such an order (starting with metastatic CNS trials) \n",
    "# helps to overcome the problem of binning into multiple bins later \n",
    "# and decreases the amount of manual screening needed at further steps. \n",
    "# Trials filtered as CNS at this step were reviewed manually. \n",
    "# If any inaccuracies were found, the correct bin was assigned by specifying it manually.\n",
    "\n",
    "for index, _ in filtered_data.iterrows():\n",
    "    condition = filtered_data['Conditions'][index]\n",
    "    title = filtered_data['Study Title'][index]\n",
    "    if ('FILTERED_' not in condition and not find('non-met', title) and not find('non met', title) \n",
    "        and not find('non-met', condition) and not find('non met', condition) \n",
    "        and not find('nonmet', title) and not find('nonmet', condition) \n",
    "        and (find('metasta', condition) or find('metasta', title)) \n",
    "        and (find('brain', title) or find('brain', condition) \n",
    "        or find('cns', title) or find('cns', condition)) \n",
    "        and not find('non-cns', condition) and not find('non-cns', title)):             \n",
    "        filtered_data.loc[index, 'Conditions'] = 'FILTERED_CNS'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02476f02",
   "metadata": {},
   "source": [
    "### IV) Define a filter for rest of the bins and sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7df497e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `locations` dictionary was defined through an iterative process \n",
    "# to cover as many trials as possible without manual screening. \n",
    "# There is a chance that this dictionary may not be sufficient \n",
    "# for similar analyses on a different dataset, \n",
    "# as it is dataset-specific and was designed primarily to sort the current trials.\n",
    "\n",
    "locations = {\n",
    "    'FILTERED_Breast': ['breast', 'ductal carcinoma'],\n",
    "    \n",
    "    'FILTERED_Digestive': ['rect', 'intestin', 'gastr', 'pancr', 'liver', 'esophag', 'œsophag',\n",
    "                           'anal', 'biliary', 'hepatocel', 'abdominal', 'cholangiocarcinoma',\n",
    "                           'anus', 'stomach', 'HCC', 'colon', 'cholangiocellular carcinoma', \n",
    "                           'GIST', 'ESCC', 'hepatic metastasis'],\n",
    "    \n",
    "    'FILTERED_Thoracic': ['lung','thym', 'pleural', 'mediastinal', 'pancoast', 'NSCLC', 'SCLC', \n",
    "                          'mesothelioma', 'thyroid'],\n",
    "    \n",
    "    'FILTERED_Genitourinary': ['prostat', 'bladder', 'kidney', 'penile', 'renal', 'urothel', 'penis',\n",
    "                               'testicular', 'seminoma', 'wilms tumor', 'adrenocortical carcinoma'],\n",
    "    \n",
    "    'FILTERED_Gynecology': ['endometr', 'ovar', 'cervi', 'vulva', 'vagin', 'pelv', 'uter', \n",
    "                            'gynecologic cancer', 'gynecological malignancies'],\n",
    "    \n",
    "    'FILTERED_Hematology': ['leukemia', 'leukaemia', 'lymphoma', 'myeloma', 'hemato', 'myelofibros',\n",
    "                            'blood cancer', 'plasmacytoma', 'mycosis fungoides', 'spine metastases'],\n",
    "    \n",
    "    'FILTERED_CNS': ['brain', 'spinal', 'glio', 'cns', 'central nervous system', 'astrocytoma', \n",
    "                     'intracranial germ cell tumors', 'ependymoma', 'medulloblastoma', 'choroid plexus',\n",
    "                     'intracranial germinoma', 'hemangioma of vertebral column', 'vestibular schwannoma',\n",
    "                     'acoustic neuroma', 'cerebellar metastases', 'neoplasm to the spine', \n",
    "                     'leptomeningeal', 'vertebral metastasis'],\n",
    "    \n",
    "    'FILTERED_HeadAndNeck': ['oral', 'pharyn', 'laryn', 'salivary', 'sinonasal', 'head and neck', \n",
    "                             'Head and Neck', 'OSCC', 'HNSCC', 'nasal', 'Head & Neck', 'H&N',\n",
    "                             'meningioma', 'adenoid', 'skull', 'nasopharyng', 'NPC', 'mouth neoplasms']\n",
    "}\n",
    "\n",
    "def check_category_overlap(text, locations):\n",
    "    category_hits = set()\n",
    "    for category, keywords in locations.items():\n",
    "        for keyword in keywords:\n",
    "            if find(keyword, text):\n",
    "                category_hits.add(category)\n",
    "    return category_hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "202b3b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, we bin with respect to 'conditions' because, \n",
    "# according to ClinicalTrials.gov: In the 'Condition' field, \n",
    "# authors should specify the disease, disorder, syndrome, \n",
    "# illness, or injury that is being studied. \n",
    "#\n",
    "# This phase was performed without any manual screening\n",
    "# and uniquely defined bins for more than 3,500 trials.\n",
    "\n",
    "for index, row in filtered_data.iterrows():\n",
    "    condition = row['Conditions']\n",
    "    \n",
    "    condition_categories = check_category_overlap(condition, locations)\n",
    "    \n",
    "    if 'FILTERED_' not in condition and len(condition_categories.union(condition_categories)) == 1:\n",
    "        filtered_data.loc[index, 'Conditions'] = next(iter(condition_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fa74faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If it was not possible to uniquely define a bin through conditions alone, \n",
    "# then for the trials where no bins were defined from conditions, \n",
    "# bins were determined from the title if bin was unique to a title.\n",
    "#\n",
    "# In cases where conditions led to more than one bin being defined, \n",
    "# the trial's title and conditions were manually screened, \n",
    "# with priority given to the title; \n",
    "#\n",
    "# Any detected inaccuracies were corrected manually.\n",
    "# After manual correction, by combining both filters, \n",
    "# we end up with the following filter, \n",
    "# which only processes the trials where the bin was not defined based on conditions \n",
    "# and is now correctly and uniquely defined based on the title. \n",
    "# With all exceptions being already corrected manually.\n",
    "\n",
    "for index, row in filtered_data.iterrows():\n",
    "    condition = row['Conditions']\n",
    "    title = row['Study Title']\n",
    "    \n",
    "    condition_categories = check_category_overlap(condition, locations)\n",
    "    title_categories = check_category_overlap(title, locations)\n",
    "        \n",
    "    if 'FILTERED_' not in condition and len(title_categories.union(title_categories)) == 1:\n",
    "        filtered_data.loc[index, 'Conditions'] = next(iter(title_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3fb3ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, manual screening of trials with zero defined bins for both titles and conditions was performed. \n",
    "# As a result, some bins were mannualy corrected, while the rest were assigned to \"Others\" bin.\n",
    "\n",
    "for index, row in filtered_data.iterrows():\n",
    "    condition = row['Conditions']\n",
    "    title = row['Study Title']\n",
    "    \n",
    "    condition_categories = check_category_overlap(condition, locations)\n",
    "    title_categories = check_category_overlap(title, locations)\n",
    "        \n",
    "    if ('FILTERED_' not in condition \n",
    "        and len(condition_categories.union(condition_categories)) == 0 \n",
    "        and len(title_categories.union(title_categories)) == 0):\n",
    "\n",
    "        filtered_data.loc[index, 'Conditions'] = 'FILTERED_Others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6345aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rest of the trials were again manually screened before assigning them to the 'Others' bin.\n",
    "# If any incorrectness was found, the correct bin was assigned manually.\n",
    "\n",
    "for index, row in filtered_data.iterrows():\n",
    "    condition = row['Conditions']\n",
    "    title = row['Study Title']\n",
    "    \n",
    "    condition_categories = check_category_overlap(condition, locations)\n",
    "    title_categories = check_category_overlap(title, locations)\n",
    "    \n",
    "    if 'FILTERED_' not in condition:\n",
    "        filtered_data.loc[index, 'Conditions'] = 'FILTERED_Others'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429dfbb",
   "metadata": {},
   "source": [
    "# Data Refining Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed2072c",
   "metadata": {},
   "source": [
    "### I) Extraction of the Geographical Location of the Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eacf7757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the most challenging part - binning pipeline, \n",
    "# we need to make our data look more 'presentable' for the analysis phase. \n",
    "# We would start by resolving the location of the trials.\n",
    "#\n",
    "# The following binning completely covers all countries in our dataset\n",
    "#. \n",
    "# Any inaccuracies in the assignment of a country to the continent do not represent \n",
    "# any of the authors opinons and are random.\n",
    "\n",
    "Europe = ['Austria', 'Belarus', 'Belgium', 'Bulgaria', 'Croatia', 'Cyprus', \n",
    "          'Czechia', 'Denmark', 'Finland', 'France', 'Georgia', 'Germany',\n",
    "          'Greece', 'Hungary', 'Ireland', 'Italy', 'Lithuania', 'Netherlands',\n",
    "          'Norway', 'Poland', 'Portugal', 'Romania', 'Serbia', 'Slovenia',\n",
    "          'Spain', 'Sweden', 'Switzerland', 'Czech Republic', 'United Kingdom',\n",
    "          'Ukraine', 'Slovakia', 'Monaco', 'Malta', 'Luxembourg', 'Latvia',\n",
    "          'Iceland', 'Estonia', 'Bosnia and Herzegovina', 'Macedonia', 'Jersey']\n",
    "\n",
    "Africa = ['South Africa', 'Algeria', 'Burkina Faso', 'Egypt', 'Ethiopia', 'Gabon',\n",
    "          'Ghana', 'Guinea', 'Kenya', 'Mali', 'Nigeria', 'Tanzania', 'Tunisia',\n",
    "          'Zambia', 'Zimbabwe', 'Uganda', 'Morocco', 'Equatorial Guinea']\n",
    "\n",
    "Asia =['Arabia', 'Armenia', 'Azerbaijan', 'Bangladesh', 'India', 'Indonesia', \n",
    "       'Iraq', 'Israel', 'Japan', 'Jordan', 'Kuwait', 'Kyrgyzstan', 'Lebanon',\n",
    "       'Malaysia', 'Kazakhstan', 'Pakistan', 'Philippines', 'Singapore',\n",
    "       'Taiwan', 'Thailand', 'Turkey', 'Vietnam', 'Uzbekistan', 'Syrian Arab Republic',\n",
    "       'Sri Lanka', 'Saudi Arabia', 'Russian Federation', 'Myanmar', 'Mongolia', \n",
    "       'Hong Kong', 'Brunei Darussalam', 'Iran', 'Korea', 'China']\n",
    "\n",
    "South_America = ['Argentina', 'Brazil', 'Chile', 'Colombia', 'Ecuador', 'Uruguay', 'Peru']\n",
    "\n",
    "North_America = ['Canada', 'Cuba', 'Guadeloupe', 'Guatemala', 'Martinique',  'Mexico',\n",
    "                 'United States', 'Trinidad and Tobago', 'Puerto Rico', 'Panama', \n",
    "                 'El Salvador', 'Dominican Republic', 'Costa Rica']\n",
    "\n",
    "Oceania = ['Australia', 'New Zealand', 'Guam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddbaa9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some countries should be modified to extract correct geographical location.\n",
    "\n",
    "filtered_data.loc[9390, 'Locations'] = filtered_data['Locations'][9390].replace('California Cancer Consortium', 'United States')\n",
    "index_to_change = [6449, 9711]\n",
    "for index in index_to_change:\n",
    "     filtered_data.loc[index,'Locations'] = filtered_data['Locations'][index].replace('Islamic Republic of', 'Iran')\n",
    "index_to_change = [6806, 6847]\n",
    "for index in index_to_change:\n",
    "     filtered_data.loc[index,'Locations'] = filtered_data['Locations'][index].replace('The Former Yugoslav Republic of', 'Macedonia')\n",
    "for index, _ in filtered_data.iterrows():\n",
    "    for location in filtered_data['Locations'][index].split('|'):\n",
    "        if 'Republic of' in location:\n",
    "            if location.split(',')[-2].strip() == 'Korea':\n",
    "                filtered_data.loc[index,'Locations'] = filtered_data['Locations'][index].replace('Republic of', 'Korea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4315e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We specify both countries and continents involved in the studies.\n",
    "\n",
    "filtered_data['Locations_Country'] = None \n",
    "filtered_data['Locations_Continent'] = None\n",
    "\n",
    "for index, _ in filtered_data.iterrows():\n",
    "    location = filtered_data['Locations'][index]\n",
    "    list_of_countries = []\n",
    "    for country in location.split('|'):\n",
    "        list_of_countries.append(str(country.split(',')[-1]).strip())\n",
    "    list_of_countries = np.unique(list_of_countries)\n",
    "    filtered_data.loc[index, 'Locations_Country'] = ', '.join(list_of_countries)\n",
    "    \n",
    "for index, _ in filtered_data.iterrows():\n",
    "    location = filtered_data['Locations'][index]\n",
    "    list_of_countries = []\n",
    "    for country in location.split('|'):\n",
    "        list_of_countries.append(str(country.split(',')[-1]).strip())\n",
    "    list_of_countries = np.unique(list_of_countries)\n",
    "    text =''\n",
    "    for unique_country_index in range(len(list_of_countries)):\n",
    "        unique_country = list_of_countries[unique_country_index]\n",
    "        if unique_country_index == len(list_of_countries)-1:\n",
    "            if unique_country in Europe:\n",
    "                if 'Europe' in text:\n",
    "                    pass\n",
    "                else:\n",
    "                    text += 'Europe' \n",
    "            elif unique_country in Africa:\n",
    "                if 'Africa' in text:\n",
    "                    pass\n",
    "                else:\n",
    "                    text += 'Africa'\n",
    "            elif unique_country in Asia:\n",
    "                text += 'Asia'\n",
    "            elif unique_country in South_America:\n",
    "                text += 'South_America'\n",
    "            elif unique_country in North_America:\n",
    "                text += 'North_America'\n",
    "            elif unique_country in Oceania:\n",
    "                text += 'Oceania'\n",
    "            else: \n",
    "                text += unique_country\n",
    "        else:\n",
    "            if unique_country in Europe:\n",
    "                if 'Europe' in text:\n",
    "                    pass\n",
    "                else:\n",
    "                    text += 'Europe' \n",
    "                    text += ','\n",
    "            elif unique_country in Africa:\n",
    "                if 'Africa' in text:\n",
    "                    pass\n",
    "                else:\n",
    "                    text += 'Africa' \n",
    "                    text += ','\n",
    "            elif unique_country in Asia:\n",
    "                if 'Asia' in text:\n",
    "                    pass\n",
    "                else:\n",
    "                    text += 'Asia' \n",
    "                    text += ','\n",
    "            elif unique_country in South_America:\n",
    "                if 'South_America' in text:\n",
    "                    pass\n",
    "                else:\n",
    "                    text += 'South_America' \n",
    "                    text += ','\n",
    "            elif unique_country in North_America:\n",
    "                if 'North_America' in text:\n",
    "                    pass\n",
    "                else:\n",
    "                    text += 'North_America' \n",
    "                    text += ','\n",
    "            elif unique_country in Oceania:\n",
    "                if 'Oceania' in text:\n",
    "                    pass\n",
    "                else:\n",
    "                    text += 'Oceania' \n",
    "                    text += ','\n",
    "            else: \n",
    "                text += unique_country  \n",
    "                text += ','\n",
    "    if text[-1] ==',':\n",
    "        text = text[:-1]\n",
    "    filtered_data.loc[index, 'Locations_Continent'] = text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb8c444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Age groups for each trial.\n",
    "\n",
    "for index in filtered_data.index:\n",
    "    study_age = filtered_data['Age'][index]\n",
    "    filtered_data.loc[index,'Age'] = None\n",
    "    try: \n",
    "        to_print = study_age.split('\\xa0')[1].replace('(','')\n",
    "        to_print = to_print.replace(')','')\n",
    "        filtered_data.loc[index,'Age'] = to_print.strip()\n",
    "    except IndexError:\n",
    "        filtered_data.loc[index,'Age'] = study_age.split('\\xa0')[0].strip()\n",
    "replace_values = {'ADULT, OLDER_ADULT': 'Adult, Older Adult', 'CHILD, ADULT, OLDER_ADULT': 'Child, Adult, Older Adult',\n",
    "                  'CHILD, ADULT': 'Child, Adult', 'OLDER_ADULT': 'Older Adult', 'ADULT':'Adult', 'CHILD':'Child'}\n",
    "filtered_data['Age'] = filtered_data['Age'].replace(replace_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "664ac281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial status was split into “ongoing” (if study status was “not yet recruiting”,\n",
    "# “recruiting”, “enrolling by invitation”, “active not recruiting” or “suspended”),\n",
    "# “stopped early” (if study status was “terminated” or “withdrawn”), \n",
    "# or “completed” (if study status was “completed”), and “unknown”. \n",
    "\n",
    "for index, _ in filtered_data.iterrows():\n",
    "    study = filtered_data['Study Status'][index]\n",
    "    if 'TERMINATED' in study or 'WITHDRAWN' in study:\n",
    "            filtered_data.loc[index, 'Study Status'] = 'STOPPED EARLY'\n",
    "for index, _ in filtered_data.iterrows():\n",
    "    study = filtered_data['Study Status'][index]\n",
    "    if 'NOT_YET_RECRUITING' in study or 'RECRUITING' in study or 'ENROLLING_BY_INVITATION' in study or 'ACTIVE_NOT_RECRUITING' in study or 'SUSPENDED' in study:\n",
    "            filtered_data.loc[index, 'Study Status'] = 'ONGOING'\n",
    "replace_values = {'ONGOING': 'Ongoing', 'STOPPED EARLY': 'Stopped Early',\n",
    "                  'UNKNOWN': 'Unknown', 'COMPLETED': 'Completed'}\n",
    "filtered_data['Study Status'] = filtered_data['Study Status'].replace(replace_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2313e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funding source was classified into “National Institutes of Health (NIH)”,\n",
    "# “industry” and “others” based on the variable funder type. \n",
    "# For trials, where the funder type did not clearly state either NIH or industry,\n",
    "# the others category was assigned. \n",
    "\n",
    "for index, _ in filtered_data.iterrows():\n",
    "    study = filtered_data['Funder Type'][index]\n",
    "    filtered_data.loc[index, 'Funder Type'] =filtered_data['Funder Type'][index].replace('OTHER_GOV', 'OTHER')\n",
    "    filtered_data.loc[index, 'Funder Type'] =filtered_data['Funder Type'][index].replace('INDIV', 'OTHER')\n",
    "    filtered_data.loc[index, 'Funder Type'] =filtered_data['Funder Type'][index].replace('NETWORK', 'OTHER')\n",
    "    filtered_data.loc[index, 'Funder Type'] =filtered_data['Funder Type'][index].replace('FED', 'OTHER')\n",
    "replace_values = {'OTHER': 'Other', 'INDUSTRY': 'Industry'}\n",
    "filtered_data['Funder Type'] = filtered_data['Funder Type'].replace(replace_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd5781bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, _ in filtered_data.iterrows():\n",
    "    condition = filtered_data['Conditions'][index]\n",
    "    filtered_data.loc[index,'Conditions'] = filtered_data['Conditions'][index].replace(condition, \n",
    "                                                                                       condition.split('_')[1].strip())\n",
    "replace_values = {'HeadAndNeck': 'Head and Neck', 'Hematology': 'Hematology System', 'Gynecology': 'Gynecology System',\n",
    "                  'CNS':'Central Nervous System'}\n",
    "filtered_data['Conditions'] = filtered_data['Conditions'].replace(replace_values)\n",
    "\n",
    "replace_values = {'MALE': 'Male', 'ALL': 'All',\n",
    "                  'FEMALE': 'Female'}\n",
    "filtered_data['Sex'] = filtered_data['Sex'].replace(replace_values)\n",
    "\n",
    "replace_values = {'PHASE1': 'Phase I', 'PHASE2': 'Phase II',\n",
    "                  'PHASE1|PHASE2': 'Phase I & Phase II', 'PHASE4': 'Phase IV', 'PHASE3':'Phase III',\n",
    "                  'PHASE2|PHASE3':'Phase II & Phase III', 'EARLY_PHASE1': 'Early Phase I'}\n",
    "filtered_data['Phases'] = filtered_data['Phases'].replace(replace_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ace079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnescessary columns\n",
    "\n",
    "filtered_data = filtered_data.drop(['Interventions', 'Study Type', 'Study Design',\n",
    "                                    'Start Date', 'Locations', 'Original Conditions'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bc33bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to the Excel sheet\n",
    "\n",
    "filtered_data.to_excel(\"filtered_data.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c00f24c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
